{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nanang Cahyadi\\anaconda3\\envs\\tf2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'accentdb',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'ag_news_subset',\n",
       " 'ai2_arc',\n",
       " 'ai2_arc_with_ir',\n",
       " 'amazon_us_reviews',\n",
       " 'anli',\n",
       " 'answer_equivalence',\n",
       " 'arc',\n",
       " 'asqa',\n",
       " 'asset',\n",
       " 'assin2',\n",
       " 'bair_robot_pushing_small',\n",
       " 'bccd',\n",
       " 'beans',\n",
       " 'bee_dataset',\n",
       " 'beir',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'ble_wind_field',\n",
       " 'blimp',\n",
       " 'booksum',\n",
       " 'bool_q',\n",
       " 'bucc',\n",
       " 'c4',\n",
       " 'c4_wsrs',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cardiotox',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'cherry_blossoms',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar100_n',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'cifar10_n',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'clic',\n",
       " 'clinc_oos',\n",
       " 'cmaterdb',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coco_captions',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'common_voice',\n",
       " 'conll2002',\n",
       " 'conll2003',\n",
       " 'controlled_noisy_web_labels',\n",
       " 'coqa',\n",
       " 'cos_e',\n",
       " 'cosmos_qa',\n",
       " 'covid19',\n",
       " 'covid19sum',\n",
       " 'crema_d',\n",
       " 'criteo',\n",
       " 'cs_restaurants',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'd4rl_adroit_door',\n",
       " 'd4rl_adroit_hammer',\n",
       " 'd4rl_adroit_pen',\n",
       " 'd4rl_adroit_relocate',\n",
       " 'd4rl_antmaze',\n",
       " 'd4rl_mujoco_ant',\n",
       " 'd4rl_mujoco_halfcheetah',\n",
       " 'd4rl_mujoco_hopper',\n",
       " 'd4rl_mujoco_walker2d',\n",
       " 'dart',\n",
       " 'davis',\n",
       " 'deep1b',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'dementiabank',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'diamonds',\n",
       " 'div2k',\n",
       " 'dmlab',\n",
       " 'doc_nli',\n",
       " 'dolphin_number_word',\n",
       " 'domainnet',\n",
       " 'downsampled_imagenet',\n",
       " 'drop',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'e2e_cleaned',\n",
       " 'efron_morris75',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'forest_fires',\n",
       " 'fuss',\n",
       " 'gap',\n",
       " 'geirhos_conflict_stimuli',\n",
       " 'gem',\n",
       " 'genomics_ood',\n",
       " 'german_credit_numeric',\n",
       " 'gigaword',\n",
       " 'glove100_angular',\n",
       " 'glue',\n",
       " 'goemotions',\n",
       " 'gov_report',\n",
       " 'gpt3',\n",
       " 'gref',\n",
       " 'groove',\n",
       " 'grounded_scan',\n",
       " 'gsm8k',\n",
       " 'gtzan',\n",
       " 'gtzan_music_speech',\n",
       " 'hellaswag',\n",
       " 'higgs',\n",
       " 'hillstrom',\n",
       " 'horses_or_humans',\n",
       " 'howell',\n",
       " 'i_naturalist2017',\n",
       " 'i_naturalist2018',\n",
       " 'i_naturalist2021',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet2012_fewshot',\n",
       " 'imagenet2012_multilabel',\n",
       " 'imagenet2012_real',\n",
       " 'imagenet2012_subset',\n",
       " 'imagenet_a',\n",
       " 'imagenet_lt',\n",
       " 'imagenet_pi',\n",
       " 'imagenet_r',\n",
       " 'imagenet_resized',\n",
       " 'imagenet_sketch',\n",
       " 'imagenet_v2',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'irc_disentanglement',\n",
       " 'iris',\n",
       " 'istella',\n",
       " 'kddcup99',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'laion400m',\n",
       " 'lambada',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'ljspeech',\n",
       " 'lm1b',\n",
       " 'locomotion',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'lvis',\n",
       " 'malaria',\n",
       " 'math_dataset',\n",
       " 'math_qa',\n",
       " 'mctaco',\n",
       " 'media_sum',\n",
       " 'mlqa',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_lens',\n",
       " 'movie_rationales',\n",
       " 'movielens',\n",
       " 'moving_mnist',\n",
       " 'mrqa',\n",
       " 'mslr_web',\n",
       " 'mt_opt',\n",
       " 'mtnt',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_instructions',\n",
       " 'natural_questions',\n",
       " 'natural_questions_open',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'nyu_depth_v2',\n",
       " 'ogbg_molpcba',\n",
       " 'omniglot',\n",
       " 'open_images_challenge2019_detection',\n",
       " 'open_images_v4',\n",
       " 'openbookqa',\n",
       " 'opinion_abstracts',\n",
       " 'opinosis',\n",
       " 'opus',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'pass',\n",
       " 'patch_camelyon',\n",
       " 'paws_wiki',\n",
       " 'paws_x_wiki',\n",
       " 'penguins',\n",
       " 'pet_finder',\n",
       " 'pg19',\n",
       " 'piqa',\n",
       " 'places365_small',\n",
       " 'placesfull',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'protein_net',\n",
       " 'q_re_cc',\n",
       " 'qa4mre',\n",
       " 'qasc',\n",
       " 'quac',\n",
       " 'quality',\n",
       " 'quickdraw_bitmap',\n",
       " 'race',\n",
       " 'radon',\n",
       " 'reddit',\n",
       " 'reddit_disentanglement',\n",
       " 'reddit_tifu',\n",
       " 'ref_coco',\n",
       " 'resisc45',\n",
       " 'rlu_atari',\n",
       " 'rlu_atari_checkpoints',\n",
       " 'rlu_atari_checkpoints_ordered',\n",
       " 'rlu_control_suite',\n",
       " 'rlu_dmlab_explore_object_rewards_few',\n",
       " 'rlu_dmlab_explore_object_rewards_many',\n",
       " 'rlu_dmlab_rooms_select_nonmatching_object',\n",
       " 'rlu_dmlab_rooms_watermaze',\n",
       " 'rlu_dmlab_seekavoid_arena01',\n",
       " 'rlu_locomotion',\n",
       " 'rlu_rwrl',\n",
       " 'robomimic_mg',\n",
       " 'robomimic_mh',\n",
       " 'robomimic_ph',\n",
       " 'robonet',\n",
       " 'robosuite_panda_pick_place_can',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 's3o4d',\n",
       " 'salient_span_wikipedia',\n",
       " 'samsum',\n",
       " 'savee',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'schema_guided_dialogue',\n",
       " 'sci_tail',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'scrolls',\n",
       " 'sentiment140',\n",
       " 'shapes3d',\n",
       " 'sift1m',\n",
       " 'simpte',\n",
       " 'siscore',\n",
       " 'smallnorb',\n",
       " 'smartwatch_gestures',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'spoken_digit',\n",
       " 'squad',\n",
       " 'squad_question_generation',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'star_cfq',\n",
       " 'starcraft_video',\n",
       " 'stl10',\n",
       " 'story_cloze',\n",
       " 'summscreen',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'symmetric_solids',\n",
       " 'tao',\n",
       " 'tatoeba',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tedlium',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'trec',\n",
       " 'trivia_qa',\n",
       " 'tydi_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'unified_qa',\n",
       " 'universal_dependencies',\n",
       " 'unnatural_instructions',\n",
       " 'user_libri_audio',\n",
       " 'user_libri_text',\n",
       " 'vctk',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'voxceleb',\n",
       " 'voxforge',\n",
       " 'waymo_open_dataset',\n",
       " 'web_graph',\n",
       " 'web_nlg',\n",
       " 'web_questions',\n",
       " 'webvid',\n",
       " 'wider_face',\n",
       " 'wiki40b',\n",
       " 'wiki_auto',\n",
       " 'wiki_bio',\n",
       " 'wiki_dialog',\n",
       " 'wiki_table_questions',\n",
       " 'wiki_table_text',\n",
       " 'wikiann',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikipedia_toxicity_subtypes',\n",
       " 'wine_quality',\n",
       " 'winogrande',\n",
       " 'wit',\n",
       " 'wit_kaggle',\n",
       " 'wmt13_translate',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'wordnet',\n",
       " 'wsc273',\n",
       " 'xnli',\n",
       " 'xquad',\n",
       " 'xsum',\n",
       " 'xtreme_pawsx',\n",
       " 'xtreme_pos',\n",
       " 'xtreme_s',\n",
       " 'xtreme_xnli',\n",
       " 'yahoo_ltrc',\n",
       " 'yelp_polarity_reviews',\n",
       " 'yes_no',\n",
       " 'youtube_vis']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Nanang Cahyadi\\tensorflow_datasets\\cycle_gan\\horse2zebra\\2.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\n",
      "Dl Size...: 0 MiB [00:01, ? MiB/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\n"
     ]
    },
    {
     "ename": "DownloadError",
     "evalue": "Failed to get url https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip. HTTP code: 403.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDownloadError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset, metadata \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mcycle_gan/horse2zebra\u001b[39;49m\u001b[39m'\u001b[39;49m, with_info\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, as_supervised\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_call()\n\u001b[0;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m   \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m   metadata\u001b[39m.\u001b[39mmark_error()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\core\\load.py:640\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \n\u001b[0;32m    523\u001b[0m \u001b[39m`tfds.load` is a convenience method that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[39m    Split-specific information is available in `ds_info.splits`.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    634\u001b[0m dbuilder \u001b[39m=\u001b[39m _fetch_builder(\n\u001b[0;32m    635\u001b[0m     name,\n\u001b[0;32m    636\u001b[0m     data_dir,\n\u001b[0;32m    637\u001b[0m     builder_kwargs,\n\u001b[0;32m    638\u001b[0m     try_gcs,\n\u001b[0;32m    639\u001b[0m )\n\u001b[1;32m--> 640\u001b[0m _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)\n\u001b[0;32m    642\u001b[0m \u001b[39mif\u001b[39;00m as_dataset_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    643\u001b[0m   as_dataset_kwargs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\core\\load.py:499\u001b[0m, in \u001b[0;36m_download_and_prepare_builder\u001b[1;34m(dbuilder, download, download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m    498\u001b[0m   download_and_prepare_kwargs \u001b[39m=\u001b[39m download_and_prepare_kwargs \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m--> 499\u001b[0m   dbuilder\u001b[39m.\u001b[39mdownload_and_prepare(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdownload_and_prepare_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_call()\n\u001b[0;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m   \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m   metadata\u001b[39m.\u001b[39mmark_error()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:646\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, download_dir, download_config, file_format)\u001b[0m\n\u001b[0;32m    644\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mread_from_directory(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_dir)\n\u001b[0;32m    645\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 646\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[0;32m    647\u001b[0m       dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[0;32m    648\u001b[0m       download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m    649\u001b[0m   )\n\u001b[0;32m    651\u001b[0m   \u001b[39m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[0;32m    652\u001b[0m   \u001b[39m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[0;32m    653\u001b[0m   \u001b[39m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[0;32m    654\u001b[0m   \u001b[39m# when reading from package data.\u001b[39;00m\n\u001b[0;32m    655\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdownload_size \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39mdownloaded_size\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1498\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1497\u001b[0m   optional_pipeline_kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1498\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_generators(  \u001b[39m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m     dl_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptional_pipeline_kwargs\n\u001b[0;32m   1500\u001b[0m )\n\u001b[0;32m   1501\u001b[0m \u001b[39m# TODO(tfds): Could be removed once all datasets are migrated.\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[39m# https://github.com/tensorflow/datasets/issues/2537\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[39m# Legacy mode (eventually convert list[SplitGeneratorLegacy] -> dict)\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m split_generators \u001b[39m=\u001b[39m split_builder\u001b[39m.\u001b[39mnormalize_legacy_split_generators(\n\u001b[0;32m   1505\u001b[0m     split_generators\u001b[39m=\u001b[39msplit_generators,\n\u001b[0;32m   1506\u001b[0m     generator_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_examples,\n\u001b[0;32m   1507\u001b[0m     is_beam\u001b[39m=\u001b[39m\u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, BeamBasedBuilder),\n\u001b[0;32m   1508\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\image_classification\\cycle_gan.py:117\u001b[0m, in \u001b[0;36mCycleGAN._split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns SplitGenerators.\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m url \u001b[39m=\u001b[39m _DL_URLS[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder_config\u001b[39m.\u001b[39mname]\n\u001b[1;32m--> 117\u001b[0m data_dirs \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39;49mdownload_and_extract(url)\n\u001b[0;32m    119\u001b[0m path_to_dataset \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_dirs, tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mlistdir(data_dirs)[\u001b[39m0\u001b[39m])\n\u001b[0;32m    121\u001b[0m train_a_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path_to_dataset, \u001b[39m\"\u001b[39m\u001b[39mtrainA\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:687\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_downloader\u001b[39m.\u001b[39mtqdm():\n\u001b[0;32m    686\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extractor\u001b[39m.\u001b[39mtqdm():\n\u001b[1;32m--> 687\u001b[0m     \u001b[39mreturn\u001b[39;00m _map_promise(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_extract, url_or_urls)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:830\u001b[0m, in \u001b[0;36m_map_promise\u001b[1;34m(map_fn, all_inputs)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[0;32m    827\u001b[0m all_promises \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m    828\u001b[0m     map_fn, all_inputs\n\u001b[0;32m    829\u001b[0m )  \u001b[39m# Apply the function\u001b[39;00m\n\u001b[1;32m--> 830\u001b[0m res \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[0;32m    831\u001b[0m     \u001b[39mlambda\u001b[39;49;00m p: p\u001b[39m.\u001b[39;49mget(), all_promises\n\u001b[0;32m    832\u001b[0m )  \u001b[39m# Wait promises\u001b[39;00m\n\u001b[0;32m    833\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\Nanang Cahyadi\\anaconda3\\envs\\tf2\\lib\\site-packages\\tree\\__init__.py:435\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39mfor\u001b[39;00m other \u001b[39min\u001b[39;00m structures[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m    433\u001b[0m   assert_same_structure(structures[\u001b[39m0\u001b[39m], other, check_types\u001b[39m=\u001b[39mcheck_types)\n\u001b[0;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m unflatten_as(structures[\u001b[39m0\u001b[39m],\n\u001b[1;32m--> 435\u001b[0m                     [func(\u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[1;32mc:\\Users\\Nanang Cahyadi\\anaconda3\\envs\\tf2\\lib\\site-packages\\tree\\__init__.py:435\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39mfor\u001b[39;00m other \u001b[39min\u001b[39;00m structures[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m    433\u001b[0m   assert_same_structure(structures[\u001b[39m0\u001b[39m], other, check_types\u001b[39m=\u001b[39mcheck_types)\n\u001b[0;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m unflatten_as(structures[\u001b[39m0\u001b[39m],\n\u001b[1;32m--> 435\u001b[0m                     [func(\u001b[39m*\u001b[39;49margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:831\u001b[0m, in \u001b[0;36m_map_promise.<locals>.<lambda>\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[0;32m    827\u001b[0m all_promises \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m    828\u001b[0m     map_fn, all_inputs\n\u001b[0;32m    829\u001b[0m )  \u001b[39m# Apply the function\u001b[39;00m\n\u001b[0;32m    830\u001b[0m res \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m--> 831\u001b[0m     \u001b[39mlambda\u001b[39;00m p: p\u001b[39m.\u001b[39;49mget(), all_promises\n\u001b[0;32m    832\u001b[0m )  \u001b[39m# Wait promises\u001b[39;00m\n\u001b[0;32m    833\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\promise\\promise.py:512\u001b[0m, in \u001b[0;36mPromise.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    510\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_target()\n\u001b[0;32m    511\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait(timeout \u001b[39mor\u001b[39;00m DEFAULT_TIMEOUT)\n\u001b[1;32m--> 512\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_target_settled_value(_raise\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\promise\\promise.py:516\u001b[0m, in \u001b[0;36mPromise._target_settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_target_settled_value\u001b[39m(\u001b[39mself\u001b[39m, _raise\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[39m# type: (bool) -> Any\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_target()\u001b[39m.\u001b[39;49m_settled_value(_raise)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\promise\\promise.py:226\u001b[0m, in \u001b[0;36mPromise._settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39mif\u001b[39;00m _raise:\n\u001b[0;32m    225\u001b[0m     raise_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fulfillment_handler0\n\u001b[1;32m--> 226\u001b[0m     reraise(\u001b[39mtype\u001b[39;49m(raise_val), raise_val, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_traceback)\n\u001b[0;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fulfillment_handler0\n",
      "File \u001b[1;32mc:\\Users\\Nanang Cahyadi\\anaconda3\\envs\\tf2\\lib\\site-packages\\six.py:719\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[0;32m    718\u001b[0m         \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 719\u001b[0m     \u001b[39mraise\u001b[39;00m value\n\u001b[0;32m    720\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    721\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\promise\\promise.py:844\u001b[0m, in \u001b[0;36m_process_future_result.<locals>.handle_future_result\u001b[1;34m(future)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandle_future_result\u001b[39m(future):\n\u001b[0;32m    842\u001b[0m     \u001b[39m# type: (Any) -> None\u001b[39;00m\n\u001b[0;32m    843\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 844\u001b[0m         resolve(future\u001b[39m.\u001b[39;49mresult())\n\u001b[0;32m    845\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    846\u001b[0m         tb \u001b[39m=\u001b[39m exc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Nanang Cahyadi\\anaconda3\\envs\\tf2\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Nanang Cahyadi\\anaconda3\\envs\\tf2\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nanang Cahyadi\\anaconda3\\envs\\tf2\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\core\\download\\downloader.py:229\u001b[0m, in \u001b[0;36m_Downloader._sync_download\u001b[1;34m(self, url, destination_path, verify)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnimplementedError:\n\u001b[0;32m    227\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[39mwith\u001b[39;00m _open_url(url, verify\u001b[39m=\u001b[39mverify) \u001b[39mas\u001b[39;00m (response, iter_content):\n\u001b[0;32m    230\u001b[0m   fname \u001b[39m=\u001b[39m _get_filename(response)\n\u001b[0;32m    231\u001b[0m   path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(destination_path, fname)\n",
      "File \u001b[1;32mc:\\Users\\Nanang Cahyadi\\anaconda3\\envs\\tf2\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[0;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\core\\download\\downloader.py:302\u001b[0m, in \u001b[0;36m_open_with_requests\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m   url \u001b[39m=\u001b[39m _normalize_drive_url(url)\n\u001b[0;32m    301\u001b[0m \u001b[39mwith\u001b[39;00m session\u001b[39m.\u001b[39mget(url, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m response:\n\u001b[1;32m--> 302\u001b[0m   _assert_status(response)\n\u001b[0;32m    303\u001b[0m   \u001b[39myield\u001b[39;00m (response, response\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39mio\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\core\\download\\downloader.py:329\u001b[0m, in \u001b[0;36m_assert_status\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Ensure the URL response is 200.\"\"\"\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m--> 329\u001b[0m   \u001b[39mraise\u001b[39;00m DownloadError(\n\u001b[0;32m    330\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mFailed to get url \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. HTTP code: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    331\u001b[0m           response\u001b[39m.\u001b[39murl, response\u001b[39m.\u001b[39mstatus_code\n\u001b[0;32m    332\u001b[0m       )\n\u001b[0;32m    333\u001b[0m   )\n",
      "\u001b[1;31mDownloadError\u001b[0m: Failed to get url https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip. HTTP code: 403."
     ]
    }
   ],
   "source": [
    "dataset, metadata = tfds.load('cycle_gan/horse2zebra', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
